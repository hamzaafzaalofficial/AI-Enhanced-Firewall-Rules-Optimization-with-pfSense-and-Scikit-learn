{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10513627,"sourceType":"datasetVersion","datasetId":6507823}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ndef process_firewall_logs(file_path):\n    \"\"\"\n    Process pfSense firewall logs and convert them to a structured DataFrame\n    \n    Parameters:\n    file_path (str): Path to the firewall log file\n    \n    Returns:\n    pandas.DataFrame: Structured firewall log data\n    \"\"\"\n    # Define column names based on pfSense filterlog format\n    columns = [\n        'rule_number',\n        'sub_rule_number',\n        'anchor',\n        'tracker',\n        'interface',\n        'reason',\n        'action',\n        'direction',\n        'ip_version',\n        'tos',\n        'ecn',\n        'ttl',\n        'id',\n        'offset',\n        'flags',\n        'protocol_id',\n        'protocol',\n        'length',\n        'source_ip',\n        'destination_ip',\n        'source_port',\n        'destination_port',\n        'data_length'\n    ]\n    \n    # Read the log file\n    # Skip the first part of each line (timestamp and pfSense filterlog[xxxxx]:)\n    # and split the remaining part by commas\n    data = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            # Extract the relevant part after 'filterlog[xxxxx]:'\n            parts = line.strip().split('filterlog[')\n            if len(parts) > 1:\n                log_data = parts[1].split(':', 1)[1].strip().split(',')\n                data.append(log_data)\n    \n    # Create DataFrame\n    df = pd.DataFrame(data, columns=columns)\n    \n    # Add timestamp column from the original log\n    timestamps = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            # Extract timestamp (first part of the line before filterlog)\n            timestamp = ' '.join(line.split()[:3])\n            timestamps.append(timestamp)\n    \n    df.insert(0, 'timestamp', timestamps)\n    \n    # Convert timestamp to datetime\n    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%b %d %H:%M:%S')\n    \n    # Clean up numeric columns\n    numeric_columns = ['rule_number', 'tracker', 'ttl', 'id', 'offset', \n                      'length', 'source_port', 'destination_port', 'data_length']\n    for col in numeric_columns:\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:12:01.138785Z","iopub.execute_input":"2025-01-19T11:12:01.139104Z","iopub.status.idle":"2025-01-19T11:12:01.442449Z","shell.execute_reply.started":"2025-01-19T11:12:01.139076Z","shell.execute_reply":"2025-01-19T11:12:01.441645Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Assuming your log file is uploaded to Kaggle\ndf = process_firewall_logs('/kaggle/input/firewall-export-logs/firewall_export (1).log')\n\n# View the first few rows and data types\nprint(df.head())\n#print(\"\\nDataset Info:\")\n#print(df.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:12:10.210560Z","iopub.execute_input":"2025-01-19T11:12:10.210953Z","iopub.status.idle":"2025-01-19T11:12:10.265514Z","shell.execute_reply.started":"2025-01-19T11:12:10.210928Z","shell.execute_reply":"2025-01-19T11:12:10.264600Z"}},"outputs":[{"name":"stdout","text":"            timestamp  rule_number sub_rule_number anchor  tracker interface  \\\n0 1900-01-17 10:19:33           68                           12009       em0   \n1 1900-01-17 10:19:34           68                           12009       em0   \n2 1900-01-17 10:19:34           68                           12009       em0   \n3 1900-01-17 10:19:34           68                           12009       em0   \n4 1900-01-17 10:19:35           68                           12009       em0   \n\n  reason action direction ip_version  ... offset flags  protocol_id  protocol  \\\n0  match  block        in          4  ...      0    DF           17       udp   \n1  match  block        in          4  ...      0    DF           17       udp   \n2  match  block        in          4  ...      0    DF           17       udp   \n3  match  block        in          4  ...      0    DF           17       udp   \n4  match  block        in          4  ...      0    DF           17       udp   \n\n   length    source_ip destination_ip source_port  destination_port  \\\n0     391  192.168.1.4  192.168.1.255        5684              5684   \n1     391  192.168.1.4  192.168.1.255        5684              5684   \n2     391  192.168.1.4  192.168.1.255        5684              5684   \n3     391  192.168.1.4  192.168.1.255        5684              5684   \n4     391  192.168.1.4  192.168.1.255        5684              5684   \n\n  data_length  \n0         371  \n1         371  \n2         371  \n3         371  \n4         371  \n\n[5 rows x 24 columns]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\ndef process_firewall_logs(file_path):\n    \"\"\"\n    Process pfSense firewall logs and convert them to a structured DataFrame with specific columns\n    and one-hot encoding for categorical variables\n    \n    Parameters:\n    file_path (str): Path to the firewall log file\n    \n    Returns:\n    pandas.DataFrame: Structured firewall log data with selected columns and encoded categorical variables\n    \"\"\"\n    # Define initial column names based on pfSense filterlog format\n    columns = [\n        'rule_number',\n        'sub_rule_number',\n        'anchor',\n        'tracker',\n        'interface',\n        'reason',\n        'action',\n        'direction',\n        'ip_version',\n        'tos',\n        'ecn',\n        'ttl',\n        'id',\n        'offset',\n        'flags',\n        'protocol_id',\n        'protocol',\n        'length',\n        'source_ip',\n        'destination_ip',\n        'source_port',\n        'destination_port',\n        'data_length'\n    ]\n    \n    # Read the log file\n    data = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            parts = line.strip().split('filterlog[')\n            if len(parts) > 1:\n                log_data = parts[1].split(':', 1)[1].strip().split(',')\n                data.append(log_data)\n    \n    # Create initial DataFrame\n    df = pd.DataFrame(data, columns=columns)\n    \n    # Select and rename required columns\n    traffic_data = df[[\n        'source_ip',\n        'destination_ip',\n        'source_port',\n        'destination_port',\n        'protocol',\n        'action'\n    ]].copy()\n    \n    # Rename columns to match the requested format\n    traffic_data.columns = ['src_ip', 'dst_ip', 'src_port', 'dst_port', 'protocol', 'action']\n    \n    # Convert ports to numeric\n    traffic_data['src_port'] = pd.to_numeric(traffic_data['src_port'], errors='coerce')\n    traffic_data['dst_port'] = pd.to_numeric(traffic_data['dst_port'], errors='coerce')\n    \n    # Apply one-hot encoding to protocol and action columns\n    traffic_data = pd.get_dummies(traffic_data, columns=['protocol', 'action'])\n    \n    return traffic_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:12:14.401642Z","iopub.execute_input":"2025-01-19T11:12:14.401947Z","iopub.status.idle":"2025-01-19T11:12:14.408301Z","shell.execute_reply.started":"2025-01-19T11:12:14.401917Z","shell.execute_reply":"2025-01-19T11:12:14.407446Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Process the log file\ntraffic_data = process_firewall_logs('/kaggle/input/firewall-export-logs/firewall_export (1).log')\n\n# View the results\nprint(\"First few rows:\")\nprint(traffic_data.head())\nprint(\"\\nColumn names:\")\nprint(traffic_data.columns.tolist())\nprint(\"\\nData types:\")\nprint(traffic_data.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:12:20.986343Z","iopub.execute_input":"2025-01-19T11:12:20.986651Z","iopub.status.idle":"2025-01-19T11:12:21.006344Z","shell.execute_reply.started":"2025-01-19T11:12:20.986622Z","shell.execute_reply":"2025-01-19T11:12:21.005502Z"}},"outputs":[{"name":"stdout","text":"First few rows:\n        src_ip         dst_ip  src_port  dst_port  protocol_udp  action_block\n0  192.168.1.4  192.168.1.255      5684      5684          True          True\n1  192.168.1.4  192.168.1.255      5684      5684          True          True\n2  192.168.1.4  192.168.1.255      5684      5684          True          True\n3  192.168.1.4  192.168.1.255      5684      5684          True          True\n4  192.168.1.4  192.168.1.255      5684      5684          True          True\n\nColumn names:\n['src_ip', 'dst_ip', 'src_port', 'dst_port', 'protocol_udp', 'action_block']\n\nData types:\nsrc_ip          object\ndst_ip          object\nsrc_port         int64\ndst_port         int64\nprotocol_udp      bool\naction_block      bool\ndtype: object\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.tree import DecisionTreeClassifier\nimport numpy as np\n\ndef analyze_network_traffic(traffic_data):\n    \"\"\"\n    Analyze network traffic using both clustering and classification approaches\n    \n    Parameters:\n    traffic_data (pd.DataFrame): Preprocessed traffic data with columns for src_ip, dst_ip, src_port, dst_port,\n                                protocol_udp, and action_block\n    \n    Returns:\n    dict: Dictionary containing analysis results and rule suggestions\n    \"\"\"\n    # Create a copy of the data to avoid modifying the original\n    analysis_data = traffic_data.copy()\n    \n    # Convert IP addresses to numerical values\n    analysis_data['src_ip_num'] = pd.factorize(analysis_data['src_ip'])[0]\n    analysis_data['dst_ip_num'] = pd.factorize(analysis_data['dst_ip'])[0]\n    \n    # 1. Clustering Analysis\n    # Select features for clustering\n    cluster_features = analysis_data[['src_port', 'dst_port', 'src_ip_num', 'dst_ip_num']]\n    \n    # Perform KMeans clustering\n    kmeans = KMeans(n_clusters=3, random_state=42)\n    analysis_data['cluster'] = kmeans.fit_predict(cluster_features)\n    \n    # Analyze clusters\n    cluster_analysis = analysis_data.groupby('cluster').agg({\n        'src_ip': 'nunique',\n        'dst_ip': 'nunique',\n        'src_port': ['mean', 'min', 'max'],\n        'dst_port': ['mean', 'min', 'max']\n    })\n    \n    # 2. Classification Analysis\n    # Prepare features for decision tree\n    feature_columns = ['src_port', 'dst_port', 'src_ip_num', 'dst_ip_num', 'protocol_udp']\n    \n    X = analysis_data[feature_columns]\n    y = analysis_data['action_block']  # Using action_block as target\n    \n    # Train decision tree\n    dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n    dt_model.fit(X, y)\n    \n    # Get feature importance\n    feature_importance = pd.Series(\n        dt_model.feature_importances_,\n        index=feature_columns\n    ).sort_values(ascending=False)\n    \n    # Generate rule suggestions based on analysis\n    rule_suggestions = []\n    \n    # Analyze clusters for potential rules\n    for cluster_id in range(3):\n        cluster_data = analysis_data[analysis_data['cluster'] == cluster_id]\n        \n        # Calculate block rate (using action_block)\n        block_rate = cluster_data['action_block'].mean()\n        \n        # If cluster has low block rate (high pass rate), suggest allowing\n        if block_rate < 0.2:\n            common_ports = cluster_data['dst_port'].mode().iloc[0]\n            rule_suggestions.append(f\"Consider creating ALLOW rule for destination port {common_ports} \"\n                                 f\"(cluster {cluster_id} shows {(1-block_rate):.1%} legitimate traffic)\")\n        \n        # If cluster has high block rate, suggest blocking\n        elif block_rate > 0.8:\n            common_ports = cluster_data['dst_port'].mode().iloc[0]\n            rule_suggestions.append(f\"Consider creating BLOCK rule for destination port {common_ports} \"\n                                 f\"(cluster {cluster_id} shows {block_rate:.1%} suspicious traffic)\")\n    \n    # Use feature importance to suggest additional rules\n    for feature, importance in feature_importance.items():\n        if importance > 0.1:  # Only suggest rules for important features\n            if feature == 'protocol_udp':\n                rule_suggestions.append(f\"UDP protocol is a significant factor \"\n                                     f\"(importance: {importance:.2f}). Consider reviewing UDP traffic rules.\")\n            elif feature in ['src_port', 'dst_port']:\n                rule_suggestions.append(f\"{feature.replace('_', ' ').title()} is a significant factor \"\n                                     f\"(importance: {importance:.2f}). Consider port-based rules.\")\n    \n    return {\n        'cluster_analysis': cluster_analysis,\n        'feature_importance': feature_importance,\n        'rule_suggestions': rule_suggestions,\n        'model': dt_model  # Return the trained model for potential future use\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:19:37.679334Z","iopub.execute_input":"2025-01-19T11:19:37.679642Z","iopub.status.idle":"2025-01-19T11:19:37.688262Z","shell.execute_reply.started":"2025-01-19T11:19:37.679619Z","shell.execute_reply":"2025-01-19T11:19:37.687402Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"results = analyze_network_traffic(traffic_data)\n\n# Print the analysis results\nprint(\"\\nCluster Analysis:\")\nprint(results['cluster_analysis'])\n\nprint(\"\\nFeature Importance:\")\nprint(results['feature_importance'])\n\nprint(\"\\nRule Suggestions:\")\nfor suggestion in results['rule_suggestions']:\n    print(f\"- {suggestion}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T11:19:42.398412Z","iopub.execute_input":"2025-01-19T11:19:42.398690Z","iopub.status.idle":"2025-01-19T11:19:42.439570Z","shell.execute_reply.started":"2025-01-19T11:19:42.398667Z","shell.execute_reply":"2025-01-19T11:19:42.438845Z"}},"outputs":[{"name":"stdout","text":"\nCluster Analysis:\n         src_ip  dst_ip      src_port                   dst_port            \n        nunique nunique          mean    min    max         mean   min   max\ncluster                                                                     \n0             1       1   5684.000000   5684   5684  5684.000000  5684  5684\n1             4       2     79.959677     67    138    79.149194    67   138\n2             1       1  46098.666667  35908  52050   137.000000   137   137\n\nFeature Importance:\nsrc_port        0.0\ndst_port        0.0\nsrc_ip_num      0.0\ndst_ip_num      0.0\nprotocol_udp    0.0\ndtype: float64\n\nRule Suggestions:\n- Consider creating BLOCK rule for destination port 5684 (cluster 0 shows 100.0% suspicious traffic)\n- Consider creating BLOCK rule for destination port 67 (cluster 1 shows 100.0% suspicious traffic)\n- Consider creating BLOCK rule for destination port 137 (cluster 2 shows 100.0% suspicious traffic)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}